# Wise2Music ğŸµ


ä¸€æ¬¾åŸºäºAIæ¨¡å‹çš„ç½‘ç»œåº”ç”¨ï¼Œèƒ½å¤Ÿé€šè¿‡æ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡éŸ³ä¹ã€‚è¯¥é¡¹ç›®èåˆäº†InspireMusicæ¨¡å‹çš„å¼ºå¤§éŸ³ä¹ç”Ÿæˆèƒ½åŠ›ä¸æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰çš„æ–‡æœ¬ç”ŸæˆæŠ€æœ¯ï¼Œä¸ºç”¨æˆ·æä¾›æµç•…çš„éŸ³ä¹åˆ›ä½œä½“éªŒã€‚

æœ¬ç¨‹åºé€šè¿‡è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæç¤ºè¯­æ–‡æœ¬ï¼Œç„¶åå¯¹æ–‡æœ¬è¿›è¡Œåˆ†æ®µæ‰§è¡Œtext-to-musicå’Œcontinuationä»»åŠ¡ï¼Œå®ç°ä½ç«¯æ˜¾å¡ä¹Ÿèƒ½è¿è¡Œè¶…é•¿éŸ³ä¹ç”Ÿæˆæ¨ç†ä»»åŠ¡ã€‚

A web application that generates high-quality music from text prompts using AI models. This project combines the power of InspireMusic models with DeepSeek's text generation capabilities to create a seamless music generation experience.

This application generates prompt text by calling a large language model, then segments the text to perform text-to-music and continuation tasks, enabling low-end graphics cards to handle ultra-long music generation inference tasks.

 ![è¿è¡Œç•Œé¢](https://raw.githubusercontent.com/willzhou/Wise2Music/main/assets/cmd.png)
 ![é¦–é¡µç•Œé¢](https://raw.githubusercontent.com/willzhou/Wise2Music/main/assets/home.png)

## Features âœ¨

- **Text-to-Music Generation**: Convert text descriptions into musical compositions
- **AI-Powered Prompt Assistant**: Get help crafting perfect music descriptions
- **Multi-Segment Music**: Generate complex compositions with intro/verse/chorus/outro sections
- **Customizable Parameters**:
  - Music style (Jazz, Classical, Electronic, etc.)
  - Mood (Happy, Sad, Energetic, etc.)
  - Duration (5-180 seconds)
  - Quality modes (High Quality vs Fast Generation)
  - Output formats (WAV, MP3, FLAC)
- **Advanced Controls**: Sample rate, fade effects, silence trimming, GPU selection

## Installation ğŸ› ï¸

1. Clone the repository:
   ```bash
   git clone https://github.com/willzhou/wise2music.git
   cd wise2music
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Set up environment variables:
   - Create a `.env` file in the root directory
   - Add your DeepSeek API key:
     ```
     DEEPSEEK_API_KEY=your_api_key_here
     ```

4. Download the InspireMusic models and place them in the `pretrained_models/` directory:
   - InspireMusic-1.5B-Long
   - InspireMusic-700M

5. Install FFmpeg (required for audio processing):
   ```bash
   # On Ubuntu/Debian
   sudo apt install ffmpeg
   
   # On MacOS
   brew install ffmpeg
   ```

## Usage ğŸš€

1. Run the Streamlit app:
   ```bash
   streamlit run app.py
   ```

2. Access the web interface in your browser at `http://localhost:8501`

3. Use the AI Prompt Assistant to generate a music description or enter your own

4. Adjust generation parameters as needed

5. Click "Generate Music" to create your composition

## Requirements ğŸ“¦

- Python 3.8+
- Streamlit
- Requests
- FFmpeg (for audio merging)
- Python-dotenv

## License ğŸ“„

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## Acknowledgments ğŸ™

- InspireMusic for the music generation models
- DeepSeek for the text generation API
- Streamlit for the web interface framework
- FFmpeg for audio processing capabilities